{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17402f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df83fa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PhoBERT loaded. Labels: ['Accepting', 'Anger', 'Disappointed', 'Disgust', 'Enjoyment', 'Fear', 'Highly Negative', 'Hopeless', 'Hurt', 'Indifferent', 'Loneliness', 'Lonely', 'Neutral', 'Other', 'Sadness', 'Spam', 'Surprise']\n"
     ]
    }
   ],
   "source": [
    "# Load PhoBERT emotion classifier\n",
    "PHOBERT_PATH = \"./phobert-emotion-final\"\n",
    "phobert_model = AutoModelForSequenceClassification.from_pretrained(PHOBERT_PATH)\n",
    "phobert_tokenizer = AutoTokenizer.from_pretrained(PHOBERT_PATH)\n",
    "\n",
    "id2label = phobert_model.config.id2label\n",
    "print(\"‚úÖ PhoBERT loaded. Labels:\", list(id2label.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827d5f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Qwen loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Ch·ªçn model Qwen nh·ªè ƒë·ªÉ ch·∫°y ƒë∆∞·ª£c tr√™n GPU/CPU ph·ªï th√¥ng\n",
    "QWEN_MODEL_NAME = \"Qwen/Qwen1.5-1.8B-Chat\"\n",
    "\n",
    "# T·∫£i tokenizer v√† model\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(QWEN_MODEL_NAME, trust_remote_code=True)\n",
    "qwen_model = AutoModelForCausalLM.from_pretrained(\n",
    "    QWEN_MODEL_NAME,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# T·∫°o pipeline chat\n",
    "qwen_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=qwen_model,\n",
    "    tokenizer=qwen_tokenizer,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Qwen loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ba1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(text):\n",
    "    \"\"\"D·ª± ƒëo√°n c·∫£m x√∫c b·∫±ng PhoBERT\"\"\"\n",
    "    inputs = phobert_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128\n",
    "    ).to(phobert_model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = phobert_model(**inputs).logits\n",
    "        pred_id = logits.argmax().item()\n",
    "    return id2label[pred_id]\n",
    "\n",
    "def generate_response(emotion, user_text, max_new_tokens=128):\n",
    "    \"\"\"Sinh ph·∫£n h·ªìi an ·ªßi b·∫±ng Qwen\"\"\"\n",
    "    # T·∫°o prompt theo c·∫£m x√∫c\n",
    "    prompt = f\"\"\"B·∫°n l√† m·ªôt ng∆∞·ªùi b·∫°n ƒë·ªìng c·∫£m v√† nh·∫π nh√†ng. \n",
    "H√£y ph·∫£n h·ªìi ng·∫Øn g·ªçn (1-2 c√¢u), ch√¢n th√†nh v√† an ·ªßi ng∆∞·ªùi ƒëang c·∫£m th·∫•y \"{emotion}\".\n",
    "Kh√¥ng c·∫ßn l·∫∑p l·∫°i c·∫£m x√∫c, ch·ªâ c·∫ßn th·ªÉ hi·ªán s·ª± th·∫•u hi·ªÉu v√† ƒë·ªông vi√™n.\n",
    "\n",
    "L·ªùi t√¢m s·ª±: \"{user_text}\"\n",
    "\n",
    "Ph·∫£n h·ªìi:\"\"\"\n",
    "    \n",
    "    response = qwen_pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=qwen_tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Tr√≠ch xu·∫•t text sinh ra\n",
    "    full_text = response[0]['generated_text']\n",
    "    reply = full_text.split(\"Ph·∫£n h·ªìi:\")[-1].strip()\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d98e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Ng∆∞·ªùi d√πng: D·∫°o n√†y m√¨nh c·∫£m th·∫•y r·∫•t c√¥ ƒë∆°n, kh√¥ng ai hi·ªÉu m√¨nh c·∫£.\n",
      "üß† C·∫£m x√∫c ph√°t hi·ªán: Sadness\n",
      "üí¨ Qwen: \"Xin l·ªói, t√¥i bi·∫øt r·∫±ng c·∫£m x√∫c nh∆∞ v·∫≠y th∆∞·ªùng c√≥ nhi·ªÅu t√°c ƒë·ªông t√≠ch c·ª±c ƒë·∫øn s·ª©c kh·ªèe v√† h·∫°nh ph√∫c c·ªßa ch√∫ng ta. T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n trong th·ªùi gian n√†y? B·∫°n c√≥ th·ªÉ n√≥i v·ªÅ nh·ªØng ƒëi·ªÅu m√† b·∫°n c·∫£m th·∫•y c√¥ ƒë∆°n nh·∫•t v√† t√¥i s·∫Ω c·ªë g·∫Øng t√¨m ki·∫øm gi·∫£i ph√°p ƒë·ªÉ gi√∫p b·∫°n tr·ªü n√™n t·ª± do h∆°n v√† ti·∫øp t·ª•c s·ªëng t·ªët ƒë·∫πp h∆°n.\"\n",
      "--------------------------------------------------------------------------------\n",
      "üí¨ Ng∆∞·ªùi d√πng: M√¨nh v·ª´a b·ªã m·∫•t vi·ªác, c·∫£m th·∫•y tuy·ªát v·ªçng qu√°.\n",
      "üß† C·∫£m x√∫c ph√°t hi·ªán: Sadness\n",
      "üí¨ Qwen: **S·ª± th√°ch th·ª©c:** T√¥i c·∫£m th·∫•y r·∫•t kh√≥ khƒÉn v√¨ t√¥i ƒë√£ l√†m vi·ªác cho c√¥ng ty n√†y h√†ng nƒÉm, v√† t√¥i kh√¥ng th·ªÉ t√¨m ƒë∆∞·ª£c m·ªôt v·ªã tr√≠ m·ªõi c√≥ th·ªÉ gi√∫p t√¥i tr·ªü v·ªÅ trong t∆∞∆°ng lai. T√¥i lu√¥n nghƒ© r·∫±ng m√¨nh s·∫Ω ti·∫øp t·ª•c l√†m vi·ªác t·ªët h∆°n trong t∆∞∆°ng lai v√† t√¥i mu·ªën ti·∫øp t·ª•c ƒë∆∞·ª£c h·ªó tr·ª£ c·ªßa c√¥ng ty ƒë·ªÉ gi√∫p t√¥i ƒë·ªëi ph√≥ v·ªõi nh·ªØng th·ª≠ th√°ch n√†y.\n",
      "**T√†i li·ªáu:** T√¥i ƒë√£ d√†nh nhi·ªÅu th·ªùi gian v√† c√¥ng s·ª©c ƒë·ªÉ gi√°o d·ª•c b·∫£n th√¢n trong lƒ©nh v·ª±c c√¥ng ngh·ªá v√† t√¥i ƒë√£ ƒë·∫°t ƒë∆∞·ª£c m·ªôt s·ªë b·∫±ng ch·ª©ng v√† b√†i t·∫≠p m√† t√¥i ƒë√£ t·∫°o ra.\n",
      "--------------------------------------------------------------------------------\n",
      "üí¨ Ng∆∞·ªùi d√πng: H√¥m nay m√¨nh r·∫•t vui v√¨ ƒë∆∞·ª£c khen tr∆∞·ªõc c·∫£ l·ªõp!\n",
      "üß† C·∫£m x√∫c ph√°t hi·ªán: Enjoyment\n",
      "üí¨ Qwen: \"Xin c·∫£m ∆°n b·∫°n ƒë√£ ƒë∆∞a ra nh·ªØng √Ω ki·∫ønÂíåÊîØÊåÅ t√¥i trong cu·ªôc s·ªëng. T√¥i ƒë√£ t√¨m th·∫•y m·ªôt c√°ch ƒë·ªÉ ti·∫øp t·ª•c tr·∫£i nghi·ªám t√¨nh y√™u v√† s·ª± h·∫°nh ph√∫c n√†y b·∫±ng c√°ch t·∫≠p trung v√†o c√°c v·∫•n ƒë·ªÅ v√† nh·∫≠n th·ª©c c·ªßa m√¨nh h∆°n. T√¥i s·∫Ω ti·∫øp t·ª•c ƒë·ªëi m·∫∑t v·ªõi nh·ªØng th·ª≠ th√°ch v√† th√°ch th·ª©c n√†y v·ªõi t∆∞ c√°ch t·ªët h∆°n v√†Êõ¥Ê∑± h∆°n, ƒë·ªÉ c√≥ th·ªÉ t·∫≠n h∆∞·ªüng h∆°n nhi·ªÅu ƒë·∫øn nh·ªØng g√¨ t√¥i l√†m. H√£y lu√¥n lu√¥n c·∫£m th·∫•y ƒëam m√™ v√† t·ª± tin khi th·ª±c hi·ªán nh·ªØng vi·ªác m√† t√¥i l√†m v√† t√¥i s·∫Ω lu√¥n lu√¥n s·∫µn s√†ng ƒë·ªÉ gi√∫p ƒë·ª° nh·ªØng ng∆∞·ªùi kh√°c trong t∆∞∆°ng lai\n",
      "--------------------------------------------------------------------------------\n",
      "üí¨ Ng∆∞·ªùi d√πng: Ch√°n n·∫£n v√¨ h·ªçc ho√†i m√† kh√¥ng ti·∫øn b·ªô.\n",
      "üß† C·∫£m x√∫c ph√°t hi·ªán: Sadness\n",
      "üí¨ Qwen: \n",
      "--------------------------------------------------------------------------------\n",
      "üí¨ Ng∆∞·ªùi d√πng: C·∫£m th·∫•y gh√©t b·∫£n th√¢n v√¨ ƒë√£ l√†m t·ªïn th∆∞∆°ng ng∆∞·ªùi kh√°c.\n",
      "üß† C·∫£m x√∫c ph√°t hi·ªán: Sadness\n",
      "üí¨ Qwen: T√¥i c·∫£m th·∫•y nh∆∞ t√¥i ƒëang ƒë·ªëi m·∫∑t v·ªõi m·ªôt qu√° tr√¨nh n∆∞·ªõc m·∫Øt quan tr·ªçng. T√¥i r·∫•t bi·∫øt r·∫±ng khi ch√∫ng ta b·∫Øt ƒë·∫ßu tr·∫£i qua nh·ªØng s·ª± c·ªë v√† kh√≥ khƒÉn, ch√∫ng ta th∆∞·ªùng c·∫£m th·∫•y ƒë∆∞·ª£c t√¢m l√Ω v·ªÅ t·ª± do v√† s·ª± t·ª± tr·ªçng h∆°n. Nh∆∞ng trong tr∆∞·ªùng h·ª£p n√†y, t√¥i th·∫•y r·∫±ng m√¨nh ƒëang b·ªã ·∫£nh h∆∞·ªüng b·ªüi t√¨nh tr·∫°ng c·ªßa ng∆∞·ªùi kh√°c v√† t√°c ƒë·ªông c·ªßa s·ª± th·∫•t b·∫°i ƒë√≥.\n",
      "T√¥i c·∫£m th·∫•y nh∆∞ t√¥i ƒëang ph·∫£i ƒë·ªëi m·∫∑t v·ªõi m·ªôt s·ª± c·ªë trong cu·ªôc s·ªëng c·ªßa m√¨nh. T√¥i c√≥ th·ªÉ nghe th·∫•y nh·ªØng l·ªùi khuy√™n t·ª´ c√°c ng∆∞·ªùi b·∫°n ƒë·ªìng c·∫£m v√† t∆∞∆°ng t·ª±, nh∆∞ng kh√¥ng th·ªÉ t√¨m ra c√°ch gi·∫£i quy·∫øt\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_messages = [\n",
    "    \"D·∫°o n√†y m√¨nh c·∫£m th·∫•y r·∫•t c√¥ ƒë∆°n, kh√¥ng ai hi·ªÉu m√¨nh c·∫£.\",\n",
    "    \"M√¨nh v·ª´a b·ªã m·∫•t vi·ªác, c·∫£m th·∫•y tuy·ªát v·ªçng qu√°.\",\n",
    "    \"H√¥m nay m√¨nh r·∫•t vui v√¨ ƒë∆∞·ª£c khen tr∆∞·ªõc c·∫£ l·ªõp!\",\n",
    "    \"Ch√°n n·∫£n v√¨ h·ªçc ho√†i m√† kh√¥ng ti·∫øn b·ªô.\",\n",
    "    \"C·∫£m th·∫•y gh√©t b·∫£n th√¢n v√¨ ƒë√£ l√†m t·ªïn th∆∞∆°ng ng∆∞·ªùi kh√°c.\"\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"üí¨ Ng∆∞·ªùi d√πng: {msg}\")\n",
    "    \n",
    "    # B∆∞·ªõc 1: D·ª± ƒëo√°n c·∫£m x√∫c\n",
    "    emotion = get_emotion(msg)\n",
    "    print(f\"üß† C·∫£m x√∫c ph√°t hi·ªán: {emotion}\")\n",
    "    \n",
    "    # B∆∞·ªõc 2: Sinh ph·∫£n h·ªìi\n",
    "    reply = generate_response(emotion, msg)\n",
    "    print(f\"üí¨ Qwen: {reply}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"üí¨ Xin ch√†o! B·∫°n c√≥ th·ªÉ chia s·∫ª b·∫•t k·ª≥ ƒëi·ªÅu g√¨ ‚Äî m√¨nh lu√¥n l·∫Øng nghe.\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nB·∫°n: \").strip()\n",
    "        if user_input.lower() in ['quit', 'exit', 'tho√°t']:\n",
    "            print(\"T·∫°m bi·ªát! ‚ù§Ô∏è\")\n",
    "            break\n",
    "        if not user_input:\n",
    "            continue\n",
    "            \n",
    "        emotion = get_emotion(user_input)\n",
    "        reply = generate_response(emotion, user_input)\n",
    "        print(f\"\\nüß† C·∫£m x√∫c: {emotion}\")\n",
    "        print(f\"üí¨ Qwen: {reply}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
