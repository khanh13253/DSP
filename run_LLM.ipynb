{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9dd7e",
   "metadata": {},
   "source": [
    "File CSV -> JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE = \"data/augmented_dataset.csv\"\n",
    "TRAIN_FILE = \"train.jsonl\"\n",
    "VAL_FILE = \"val.jsonl\"\n",
    "\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "if not {\"comment\", \"response\"}.issubset(df.columns):\n",
    "    raise ValueError(\"CSV phải có hai cột: 'comment' và 'response'!\")\n",
    "\n",
    "# Split 90% train, 10% val\n",
    "split = int(0.9 * len(df))\n",
    "train_df, val_df = df[:split], df[split:]\n",
    "\n",
    "def convert_to_jsonl(df, out_file):\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        records.append({\n",
    "            \"instruction\": \"Hãy an ủi và đồng cảm với lời tâm sự sau:\",\n",
    "            \"input\": row[\"comment\"],\n",
    "            \"output\": row[\"response\"]\n",
    "        })\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in records:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "convert_to_jsonl(train_df, TRAIN_FILE)\n",
    "convert_to_jsonl(val_df, VAL_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1643f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "OUTPUT_DIR = \"./lora_output\"\n",
    "\n",
    "rouge = load_metric(\"rouge\")\n",
    "bleu = load_metric(\"bleu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    rouge_result = rouge.compute(predictions=preds, references=labels)\n",
    "    bleu_result = bleu.compute(\n",
    "        predictions=[p.split() for p in preds],\n",
    "        references=[[l.split()] for l in labels]\n",
    "    )\n",
    "    result = {\n",
    "        \"rougeL\": rouge_result[\"rougeL\"].mid.fmeasure,\n",
    "        \"bleu\": bleu_result[\"bleu\"]\n",
    "    }\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, device_map=\"auto\", load_in_8bit=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(base, OUTPUT_DIR)\n",
    "\n",
    "def gen_reply(user_text, instruction=\"Hãy an ủi và đồng cảm với người nói\"):\n",
    "    prompt = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{user_text}\\n\\n### Response:\\n\"\n",
    "    ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    out = model.generate(**ids, max_new_tokens=256, do_sample=True, temperature=0.8)\n",
    "    txt = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    resp = txt.split(\"### Response:\")[-1].strip()\n",
    "    return resp\n",
    "\n",
    "test_text = \"Mình cảm thấy rất cô đơn, không ai quan tâm đến mình cả.\"\n",
    "print(gen_reply(test_text))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
